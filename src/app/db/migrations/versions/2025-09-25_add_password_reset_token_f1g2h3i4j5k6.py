# type: ignore
"""add_password_reset_token

Revision ID: f1g2h3i4j5k6
Revises: ebbf0db732c0
Create Date: 2025-09-25 00:00:00.000000+00:00

"""
from __future__ import annotations

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op
from advanced_alchemy.types import EncryptedString, EncryptedText, GUID, ORA_JSONB, DateTimeUTC
from sqlalchemy import Text  # noqa: F401

if TYPE_CHECKING:
    from collections.abc import Sequence

__all__ = ["downgrade", "upgrade", "schema_upgrades", "schema_downgrades", "data_upgrades", "data_downgrades"]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText

# revision identifiers, used by Alembic.
revision = 'f1g2h3i4j5k6'
down_revision = 'ebbf0db732c0'
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()

def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()

def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('password_reset_token',
    sa.Column('id', sa.GUID(length=16), nullable=False),
    sa.Column('user_id', sa.GUID(length=16), nullable=False),
    sa.Column('token', sa.String(length=64), nullable=False),
    sa.Column('expires_at', sa.DateTimeUTC(timezone=True), nullable=False),
    sa.Column('is_used', sa.Boolean(), nullable=False),
    sa.Column('used_at', sa.DateTimeUTC(timezone=True), nullable=True),
    sa.Column('sa_orm_sentinel', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTimeUTC(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTimeUTC(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['user_account.id'], name=op.f('fk_password_reset_token_user_id_user_account'), ondelete='cascade'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_password_reset_token'))
    )
    with op.batch_alter_table('password_reset_token', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_password_reset_token_token'), ['token'], unique=True)
        batch_op.create_index(batch_op.f('ix_password_reset_token_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('password_reset_token', schema=None) as batch_op:
        batch_op.create_table_comment(
        'Password reset tokens for user password recovery',
        existing_comment=None
    )

    # ### end Alembic commands ###

def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('password_reset_token', schema=None) as batch_op:
        batch_op.drop_table_comment(
        existing_comment='Password reset tokens for user password recovery'
    )

    with op.batch_alter_table('password_reset_token', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_password_reset_token_user_id'))
        batch_op.drop_index(batch_op.f('ix_password_reset_token_token'))

    op.drop_table('password_reset_token')
    # ### end Alembic commands ###

def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""

def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""